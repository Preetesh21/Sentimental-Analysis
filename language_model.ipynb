{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YWTrfLJ5aS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQTykSVYQE0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHhvSXLoAARu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/Bean.txt', 'r',encoding='utf-8') as f:\n",
        "    x = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYodquYlADCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "918d246e-b719-41e9-a476-2988b42a7df4"
      },
      "source": [
        "data=str(x)\n",
        "type(data)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3BKGY4j5lOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "025b1ca3-ccde-4e29-8534-22091fea7336"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded = tokenizer.texts_to_sequences([data])[0]\n",
        "# retrieve vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 4573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvgkv6TeCSPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1ed33b4-c0de-4743-8552-470f4937bb56"
      },
      "source": [
        "# encode 4 words -> 1 word\n",
        "sequences = list()\n",
        "for i in range(4, len(encoded)):\n",
        "\tsequence = encoded[i-4:i+1]\n",
        "\tsequences.append(sequence)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 38561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDhPYW7ECVcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e27c695-598f-4b88-ad40-6cebd1d969be"
      },
      "source": [
        "# pad sequences\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "print('Max Sequence Length: %d' % max_length)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDB04ddbCXz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into input and output elements\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOLAq_kf7J7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9bf16bc0-0065-4646-80cc-33baad2f3eed"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 4, 10)             45730     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                19200     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4573)              297245    \n",
            "=================================================================\n",
            "Total params: 362,175\n",
            "Trainable params: 362,175\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjvg47AYhadZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93e07568-79b9-49b8-dcbd-c8db20355221"
      },
      "source": [
        "model.fit(X, y, epochs=500, verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "38561/38561 [==============================] - 19s 484us/step - loss: 6.0440 - accuracy: 0.1338\n",
            "Epoch 2/500\n",
            "38561/38561 [==============================] - 19s 483us/step - loss: 5.5003 - accuracy: 0.2029\n",
            "Epoch 3/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 5.2180 - accuracy: 0.2146\n",
            "Epoch 4/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 5.0591 - accuracy: 0.2297\n",
            "Epoch 5/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 4.9117 - accuracy: 0.2441\n",
            "Epoch 6/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 4.7723 - accuracy: 0.2522\n",
            "Epoch 7/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 4.6403 - accuracy: 0.2602\n",
            "Epoch 8/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 4.5145 - accuracy: 0.2670\n",
            "Epoch 9/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 4.3918 - accuracy: 0.2740\n",
            "Epoch 10/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 4.2742 - accuracy: 0.2778\n",
            "Epoch 11/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 4.1646 - accuracy: 0.2818\n",
            "Epoch 12/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 4.0636 - accuracy: 0.2881\n",
            "Epoch 13/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 3.9660 - accuracy: 0.2928\n",
            "Epoch 14/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 3.8734 - accuracy: 0.2980\n",
            "Epoch 15/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 3.7833 - accuracy: 0.3048\n",
            "Epoch 16/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 3.6970 - accuracy: 0.3111\n",
            "Epoch 17/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 3.6138 - accuracy: 0.3154\n",
            "Epoch 18/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 3.5322 - accuracy: 0.3232\n",
            "Epoch 19/500\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 3.4556 - accuracy: 0.3325\n",
            "Epoch 20/500\n",
            "38561/38561 [==============================] - 18s 467us/step - loss: 3.3801 - accuracy: 0.3402\n",
            "Epoch 21/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 3.3096 - accuracy: 0.3482\n",
            "Epoch 22/500\n",
            "38561/38561 [==============================] - 19s 487us/step - loss: 3.2392 - accuracy: 0.3591\n",
            "Epoch 23/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 3.1733 - accuracy: 0.3653\n",
            "Epoch 24/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 3.1088 - accuracy: 0.3757\n",
            "Epoch 25/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 3.0479 - accuracy: 0.3847\n",
            "Epoch 26/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 2.9882 - accuracy: 0.3916\n",
            "Epoch 27/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.9319 - accuracy: 0.4021\n",
            "Epoch 28/500\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 2.8772 - accuracy: 0.4092\n",
            "Epoch 29/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.8245 - accuracy: 0.4176\n",
            "Epoch 30/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.7738 - accuracy: 0.4263\n",
            "Epoch 31/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 2.7253 - accuracy: 0.4324\n",
            "Epoch 32/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 2.6776 - accuracy: 0.4415\n",
            "Epoch 33/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 2.6324 - accuracy: 0.4489\n",
            "Epoch 34/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 2.5884 - accuracy: 0.4562\n",
            "Epoch 35/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 2.5465 - accuracy: 0.4626\n",
            "Epoch 36/500\n",
            "38561/38561 [==============================] - 18s 480us/step - loss: 2.5063 - accuracy: 0.4710\n",
            "Epoch 37/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 2.4660 - accuracy: 0.4786\n",
            "Epoch 38/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 2.4283 - accuracy: 0.4831\n",
            "Epoch 39/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.3934 - accuracy: 0.4894\n",
            "Epoch 40/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 2.3552 - accuracy: 0.4969\n",
            "Epoch 41/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 2.3229 - accuracy: 0.5042\n",
            "Epoch 42/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 2.2884 - accuracy: 0.5081\n",
            "Epoch 43/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 2.2586 - accuracy: 0.5148\n",
            "Epoch 44/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 2.2270 - accuracy: 0.5201\n",
            "Epoch 45/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 2.1967 - accuracy: 0.5253\n",
            "Epoch 46/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 2.1684 - accuracy: 0.5316\n",
            "Epoch 47/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 2.1398 - accuracy: 0.5363\n",
            "Epoch 48/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 2.1135 - accuracy: 0.5405\n",
            "Epoch 49/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 2.0869 - accuracy: 0.5474\n",
            "Epoch 50/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.0602 - accuracy: 0.5510\n",
            "Epoch 51/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 2.0359 - accuracy: 0.5557\n",
            "Epoch 52/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 2.0119 - accuracy: 0.5613\n",
            "Epoch 53/500\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 1.9869 - accuracy: 0.5661\n",
            "Epoch 54/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.9655 - accuracy: 0.5688\n",
            "Epoch 55/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.9422 - accuracy: 0.5733\n",
            "Epoch 56/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.9219 - accuracy: 0.5776\n",
            "Epoch 57/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.9009 - accuracy: 0.5826\n",
            "Epoch 58/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.8792 - accuracy: 0.5876\n",
            "Epoch 59/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.8592 - accuracy: 0.5910\n",
            "Epoch 60/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.8397 - accuracy: 0.5948\n",
            "Epoch 61/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 1.8234 - accuracy: 0.5975\n",
            "Epoch 62/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.8037 - accuracy: 0.6031\n",
            "Epoch 63/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.7858 - accuracy: 0.6061\n",
            "Epoch 64/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.7698 - accuracy: 0.6091\n",
            "Epoch 65/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.7508 - accuracy: 0.6121\n",
            "Epoch 66/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.7336 - accuracy: 0.6153\n",
            "Epoch 67/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.7196 - accuracy: 0.6190\n",
            "Epoch 68/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.7017 - accuracy: 0.6217\n",
            "Epoch 69/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.6874 - accuracy: 0.6252\n",
            "Epoch 70/500\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 1.6718 - accuracy: 0.6284\n",
            "Epoch 71/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.6576 - accuracy: 0.6302\n",
            "Epoch 72/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.6425 - accuracy: 0.6336\n",
            "Epoch 73/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.6266 - accuracy: 0.6374\n",
            "Epoch 74/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.6147 - accuracy: 0.6417\n",
            "Epoch 75/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.6000 - accuracy: 0.6443\n",
            "Epoch 76/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.5864 - accuracy: 0.6454\n",
            "Epoch 77/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.5748 - accuracy: 0.6487\n",
            "Epoch 78/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 1.5611 - accuracy: 0.6504\n",
            "Epoch 79/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.5479 - accuracy: 0.6520\n",
            "Epoch 80/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.5370 - accuracy: 0.6558\n",
            "Epoch 81/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.5262 - accuracy: 0.6597\n",
            "Epoch 82/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.5131 - accuracy: 0.6595\n",
            "Epoch 83/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.5010 - accuracy: 0.6634\n",
            "Epoch 84/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 1.4919 - accuracy: 0.6649\n",
            "Epoch 85/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 1.4786 - accuracy: 0.6668\n",
            "Epoch 86/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.4682 - accuracy: 0.6701\n",
            "Epoch 87/500\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 1.4595 - accuracy: 0.6732\n",
            "Epoch 88/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.4484 - accuracy: 0.6735\n",
            "Epoch 89/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.4378 - accuracy: 0.6755\n",
            "Epoch 90/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.4278 - accuracy: 0.6782\n",
            "Epoch 91/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.4178 - accuracy: 0.6806\n",
            "Epoch 92/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.4096 - accuracy: 0.6821\n",
            "Epoch 93/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.3992 - accuracy: 0.6854\n",
            "Epoch 94/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.3910 - accuracy: 0.6869\n",
            "Epoch 95/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.3800 - accuracy: 0.6887\n",
            "Epoch 96/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.3742 - accuracy: 0.6898\n",
            "Epoch 97/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.3634 - accuracy: 0.6908\n",
            "Epoch 98/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.3538 - accuracy: 0.6950\n",
            "Epoch 99/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.3473 - accuracy: 0.6945\n",
            "Epoch 100/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.3368 - accuracy: 0.6978\n",
            "Epoch 101/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.3289 - accuracy: 0.7000\n",
            "Epoch 102/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.3243 - accuracy: 0.7000\n",
            "Epoch 103/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.3141 - accuracy: 0.7018\n",
            "Epoch 104/500\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 1.3063 - accuracy: 0.7042\n",
            "Epoch 105/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.2994 - accuracy: 0.7056\n",
            "Epoch 106/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.2899 - accuracy: 0.7072\n",
            "Epoch 107/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.2832 - accuracy: 0.7096\n",
            "Epoch 108/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 1.2771 - accuracy: 0.7097\n",
            "Epoch 109/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.2688 - accuracy: 0.7108\n",
            "Epoch 110/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.2633 - accuracy: 0.7118\n",
            "Epoch 111/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.2556 - accuracy: 0.7141\n",
            "Epoch 112/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.2492 - accuracy: 0.7152\n",
            "Epoch 113/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 1.2400 - accuracy: 0.7176\n",
            "Epoch 114/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.2354 - accuracy: 0.7179\n",
            "Epoch 115/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.2279 - accuracy: 0.7208\n",
            "Epoch 116/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 1.2232 - accuracy: 0.7225\n",
            "Epoch 117/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.2166 - accuracy: 0.7230\n",
            "Epoch 118/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.2093 - accuracy: 0.7239\n",
            "Epoch 119/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.2028 - accuracy: 0.7272\n",
            "Epoch 120/500\n",
            "38561/38561 [==============================] - 18s 467us/step - loss: 1.1977 - accuracy: 0.7266\n",
            "Epoch 121/500\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 1.1900 - accuracy: 0.7295\n",
            "Epoch 122/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.1851 - accuracy: 0.7283\n",
            "Epoch 123/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.1821 - accuracy: 0.7306\n",
            "Epoch 124/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.1761 - accuracy: 0.7294\n",
            "Epoch 125/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.1695 - accuracy: 0.7321\n",
            "Epoch 126/500\n",
            "38561/38561 [==============================] - 18s 469us/step - loss: 1.1617 - accuracy: 0.7334\n",
            "Epoch 127/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.1583 - accuracy: 0.7344\n",
            "Epoch 128/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.1513 - accuracy: 0.7376\n",
            "Epoch 129/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.1468 - accuracy: 0.7372\n",
            "Epoch 130/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.1408 - accuracy: 0.7394\n",
            "Epoch 131/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.1380 - accuracy: 0.7391\n",
            "Epoch 132/500\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 1.1318 - accuracy: 0.7406\n",
            "Epoch 133/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 1.1257 - accuracy: 0.7427\n",
            "Epoch 134/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.1170 - accuracy: 0.7458\n",
            "Epoch 135/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.1166 - accuracy: 0.7428\n",
            "Epoch 136/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 1.1109 - accuracy: 0.7461\n",
            "Epoch 137/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.1052 - accuracy: 0.7459\n",
            "Epoch 138/500\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 1.1029 - accuracy: 0.7481\n",
            "Epoch 139/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.0958 - accuracy: 0.7489\n",
            "Epoch 140/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0926 - accuracy: 0.7495\n",
            "Epoch 141/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0869 - accuracy: 0.7504\n",
            "Epoch 142/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0831 - accuracy: 0.7502\n",
            "Epoch 143/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0760 - accuracy: 0.7530\n",
            "Epoch 144/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.0725 - accuracy: 0.7530\n",
            "Epoch 145/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 1.0717 - accuracy: 0.7532\n",
            "Epoch 146/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0651 - accuracy: 0.7560\n",
            "Epoch 147/500\n",
            "38561/38561 [==============================] - 17s 436us/step - loss: 1.0617 - accuracy: 0.7545\n",
            "Epoch 148/500\n",
            "38561/38561 [==============================] - 15s 400us/step - loss: 1.0545 - accuracy: 0.7576\n",
            "Epoch 149/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0499 - accuracy: 0.7572\n",
            "Epoch 150/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.0474 - accuracy: 0.7574\n",
            "Epoch 151/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 1.0445 - accuracy: 0.7590\n",
            "Epoch 152/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 1.0424 - accuracy: 0.7594\n",
            "Epoch 153/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 1.0341 - accuracy: 0.7613\n",
            "Epoch 154/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 1.0295 - accuracy: 0.7629\n",
            "Epoch 155/500\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 1.0280 - accuracy: 0.7626\n",
            "Epoch 156/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.0241 - accuracy: 0.7636\n",
            "Epoch 157/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.0196 - accuracy: 0.7647\n",
            "Epoch 158/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 1.0178 - accuracy: 0.7644\n",
            "Epoch 159/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 1.0108 - accuracy: 0.7656\n",
            "Epoch 160/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 1.0072 - accuracy: 0.7680\n",
            "Epoch 161/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 1.0063 - accuracy: 0.7656\n",
            "Epoch 162/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 0.9991 - accuracy: 0.7670\n",
            "Epoch 163/500\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 0.9994 - accuracy: 0.7667\n",
            "Epoch 164/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 0.9943 - accuracy: 0.7682\n",
            "Epoch 165/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9890 - accuracy: 0.7707\n",
            "Epoch 166/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9858 - accuracy: 0.7694\n",
            "Epoch 167/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9836 - accuracy: 0.7717\n",
            "Epoch 168/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9822 - accuracy: 0.7701\n",
            "Epoch 169/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9772 - accuracy: 0.7738\n",
            "Epoch 170/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 0.9723 - accuracy: 0.7737\n",
            "Epoch 171/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 0.9692 - accuracy: 0.7750\n",
            "Epoch 172/500\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.9665 - accuracy: 0.7745\n",
            "Epoch 173/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9635 - accuracy: 0.7768\n",
            "Epoch 174/500\n",
            "38561/38561 [==============================] - 18s 471us/step - loss: 0.9619 - accuracy: 0.7753\n",
            "Epoch 175/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9580 - accuracy: 0.7768\n",
            "Epoch 176/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 0.9530 - accuracy: 0.7783\n",
            "Epoch 177/500\n",
            "38561/38561 [==============================] - 18s 476us/step - loss: 0.9581 - accuracy: 0.7759\n",
            "Epoch 178/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9462 - accuracy: 0.7800\n",
            "Epoch 179/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 0.9410 - accuracy: 0.7799\n",
            "Epoch 180/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 0.9406 - accuracy: 0.7806\n",
            "Epoch 181/500\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.9385 - accuracy: 0.7804\n",
            "Epoch 182/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9363 - accuracy: 0.7811\n",
            "Epoch 183/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.9363 - accuracy: 0.7807\n",
            "Epoch 184/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9293 - accuracy: 0.7830\n",
            "Epoch 185/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9267 - accuracy: 0.7837\n",
            "Epoch 186/500\n",
            "38561/38561 [==============================] - 18s 474us/step - loss: 0.9219 - accuracy: 0.7853\n",
            "Epoch 187/500\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.9227 - accuracy: 0.7853\n",
            "Epoch 188/500\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.9178 - accuracy: 0.7856\n",
            "Epoch 189/500\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.9125 - accuracy: 0.7864\n",
            "Epoch 190/500\n",
            "23584/38561 [=================>............] - ETA: 7s - loss: 0.8945 - accuracy: 0.7921Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUhnebka1pFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c206251-c314-4fe0-ecc1-4dca9290b6d4"
      },
      "source": [
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.7707 - accuracy: 0.8167\n",
            "Epoch 2/100\n",
            "38561/38561 [==============================] - 19s 483us/step - loss: 0.7710 - accuracy: 0.8171\n",
            "Epoch 3/100\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.7663 - accuracy: 0.8185\n",
            "Epoch 4/100\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.7632 - accuracy: 0.8187\n",
            "Epoch 5/100\n",
            "38561/38561 [==============================] - 18s 475us/step - loss: 0.7668 - accuracy: 0.8159\n",
            "Epoch 6/100\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.7582 - accuracy: 0.8209\n",
            "Epoch 7/100\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.7674 - accuracy: 0.8163\n",
            "Epoch 8/100\n",
            "38561/38561 [==============================] - 18s 473us/step - loss: 0.7588 - accuracy: 0.8203\n",
            "Epoch 9/100\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 0.7538 - accuracy: 0.8213\n",
            "Epoch 10/100\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.7536 - accuracy: 0.8222\n",
            "Epoch 11/100\n",
            "38561/38561 [==============================] - 18s 472us/step - loss: 0.7534 - accuracy: 0.8212\n",
            "Epoch 12/100\n",
            "38561/38561 [==============================] - 18s 470us/step - loss: 0.7519 - accuracy: 0.8218\n",
            "Epoch 13/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7524 - accuracy: 0.8206\n",
            "Epoch 14/100\n",
            "38561/38561 [==============================] - 19s 489us/step - loss: 0.7504 - accuracy: 0.8199\n",
            "Epoch 15/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7538 - accuracy: 0.8216\n",
            "Epoch 16/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7433 - accuracy: 0.8230\n",
            "Epoch 17/100\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.7451 - accuracy: 0.8229\n",
            "Epoch 18/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7443 - accuracy: 0.8233\n",
            "Epoch 19/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7437 - accuracy: 0.8218\n",
            "Epoch 20/100\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.7438 - accuracy: 0.8217\n",
            "Epoch 21/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7414 - accuracy: 0.8223\n",
            "Epoch 22/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7386 - accuracy: 0.8238\n",
            "Epoch 23/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7355 - accuracy: 0.8236\n",
            "Epoch 24/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7335 - accuracy: 0.8244\n",
            "Epoch 25/100\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 0.7350 - accuracy: 0.8239\n",
            "Epoch 26/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7335 - accuracy: 0.8254\n",
            "Epoch 27/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7321 - accuracy: 0.8252\n",
            "Epoch 28/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7332 - accuracy: 0.8257\n",
            "Epoch 29/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7321 - accuracy: 0.8259\n",
            "Epoch 30/100\n",
            "38561/38561 [==============================] - 19s 484us/step - loss: 0.7285 - accuracy: 0.8265\n",
            "Epoch 31/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7258 - accuracy: 0.8280\n",
            "Epoch 32/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7278 - accuracy: 0.8271\n",
            "Epoch 33/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7219 - accuracy: 0.8264\n",
            "Epoch 34/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7234 - accuracy: 0.8271\n",
            "Epoch 35/100\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.7291 - accuracy: 0.8255\n",
            "Epoch 36/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7157 - accuracy: 0.8296\n",
            "Epoch 37/100\n",
            "38561/38561 [==============================] - 18s 480us/step - loss: 0.7172 - accuracy: 0.8281\n",
            "Epoch 38/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7184 - accuracy: 0.8274\n",
            "Epoch 39/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7170 - accuracy: 0.8287\n",
            "Epoch 40/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7155 - accuracy: 0.8291\n",
            "Epoch 41/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7153 - accuracy: 0.8286\n",
            "Epoch 42/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7145 - accuracy: 0.8278\n",
            "Epoch 43/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7133 - accuracy: 0.8306\n",
            "Epoch 44/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.7125 - accuracy: 0.8296\n",
            "Epoch 45/100\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 0.7099 - accuracy: 0.8317\n",
            "Epoch 46/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7061 - accuracy: 0.8319\n",
            "Epoch 47/100\n",
            "38561/38561 [==============================] - 19s 483us/step - loss: 0.7111 - accuracy: 0.8292\n",
            "Epoch 48/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7049 - accuracy: 0.8304\n",
            "Epoch 49/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.7059 - accuracy: 0.8309\n",
            "Epoch 50/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7069 - accuracy: 0.8310\n",
            "Epoch 51/100\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.7023 - accuracy: 0.8316\n",
            "Epoch 52/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7015 - accuracy: 0.8315\n",
            "Epoch 53/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.7003 - accuracy: 0.8318\n",
            "Epoch 54/100\n",
            "38561/38561 [==============================] - 19s 483us/step - loss: 0.7010 - accuracy: 0.8311\n",
            "Epoch 55/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.7000 - accuracy: 0.8316\n",
            "Epoch 56/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.6964 - accuracy: 0.8338\n",
            "Epoch 57/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6968 - accuracy: 0.8321\n",
            "Epoch 58/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6952 - accuracy: 0.8315\n",
            "Epoch 59/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6954 - accuracy: 0.8335\n",
            "Epoch 60/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.6964 - accuracy: 0.8326\n",
            "Epoch 61/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.6943 - accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.6882 - accuracy: 0.8352\n",
            "Epoch 63/100\n",
            "38561/38561 [==============================] - 19s 486us/step - loss: 0.6951 - accuracy: 0.8330\n",
            "Epoch 64/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.6905 - accuracy: 0.8330\n",
            "Epoch 65/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.6864 - accuracy: 0.8366\n",
            "Epoch 66/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.6865 - accuracy: 0.8354\n",
            "Epoch 67/100\n",
            "38561/38561 [==============================] - 19s 481us/step - loss: 0.6858 - accuracy: 0.8346\n",
            "Epoch 68/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6893 - accuracy: 0.8336\n",
            "Epoch 69/100\n",
            "38561/38561 [==============================] - 19s 482us/step - loss: 0.6834 - accuracy: 0.8356\n",
            "Epoch 70/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.6831 - accuracy: 0.8352\n",
            "Epoch 71/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6816 - accuracy: 0.8358\n",
            "Epoch 72/100\n",
            "38561/38561 [==============================] - 18s 479us/step - loss: 0.6840 - accuracy: 0.8349\n",
            "Epoch 73/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.6827 - accuracy: 0.8363\n",
            "Epoch 74/100\n",
            "38561/38561 [==============================] - 19s 480us/step - loss: 0.6802 - accuracy: 0.8357\n",
            "Epoch 75/100\n",
            "38561/38561 [==============================] - 18s 478us/step - loss: 0.6792 - accuracy: 0.8374\n",
            "Epoch 76/100\n",
            "38561/38561 [==============================] - 18s 477us/step - loss: 0.6796 - accuracy: 0.8372\n",
            "Epoch 77/100\n",
            "38561/38561 [==============================] - 16s 427us/step - loss: 0.6760 - accuracy: 0.8376\n",
            "Epoch 78/100\n",
            "38561/38561 [==============================] - 13s 342us/step - loss: 0.6785 - accuracy: 0.8375\n",
            "Epoch 79/100\n",
            "38561/38561 [==============================] - 13s 339us/step - loss: 0.6774 - accuracy: 0.8368\n",
            "Epoch 80/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6733 - accuracy: 0.8394\n",
            "Epoch 81/100\n",
            "38561/38561 [==============================] - 13s 345us/step - loss: 0.6760 - accuracy: 0.8373\n",
            "Epoch 82/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6717 - accuracy: 0.8381\n",
            "Epoch 83/100\n",
            "38561/38561 [==============================] - 13s 339us/step - loss: 0.6713 - accuracy: 0.8389\n",
            "Epoch 84/100\n",
            "38561/38561 [==============================] - 13s 342us/step - loss: 0.6724 - accuracy: 0.8384\n",
            "Epoch 85/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6696 - accuracy: 0.8389\n",
            "Epoch 86/100\n",
            "38561/38561 [==============================] - 13s 343us/step - loss: 0.6693 - accuracy: 0.8388\n",
            "Epoch 87/100\n",
            "38561/38561 [==============================] - 13s 339us/step - loss: 0.6675 - accuracy: 0.8396\n",
            "Epoch 88/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6706 - accuracy: 0.8389\n",
            "Epoch 89/100\n",
            "38561/38561 [==============================] - 13s 342us/step - loss: 0.6840 - accuracy: 0.8349\n",
            "Epoch 90/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6617 - accuracy: 0.8394\n",
            "Epoch 91/100\n",
            "38561/38561 [==============================] - 13s 342us/step - loss: 0.6667 - accuracy: 0.8398\n",
            "Epoch 92/100\n",
            "38561/38561 [==============================] - 13s 342us/step - loss: 0.6646 - accuracy: 0.8387\n",
            "Epoch 93/100\n",
            "38561/38561 [==============================] - 13s 338us/step - loss: 0.6631 - accuracy: 0.8406\n",
            "Epoch 94/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6619 - accuracy: 0.8404\n",
            "Epoch 95/100\n",
            "38561/38561 [==============================] - 13s 338us/step - loss: 0.6576 - accuracy: 0.8419\n",
            "Epoch 96/100\n",
            "38561/38561 [==============================] - 13s 339us/step - loss: 0.6646 - accuracy: 0.8399\n",
            "Epoch 97/100\n",
            "38561/38561 [==============================] - 13s 337us/step - loss: 0.6587 - accuracy: 0.8413\n",
            "Epoch 98/100\n",
            "38561/38561 [==============================] - 13s 343us/step - loss: 0.6556 - accuracy: 0.8427\n",
            "Epoch 99/100\n",
            "38561/38561 [==============================] - 13s 340us/step - loss: 0.6638 - accuracy: 0.8385\n",
            "Epoch 100/100\n",
            "38561/38561 [==============================] - 13s 339us/step - loss: 0.6538 - accuracy: 0.8421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1508fb7358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a10xqx527UOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pre-pad sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\treturn in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozoPVZrq7NAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "de634095-2717-4cf9-b2ca-1dbb900c51a1"
      },
      "source": [
        "print(generate_seq(model, tokenizer, max_length-1, 'Mr. Bean ', 6))\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'A group of grave',8 ))\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'BEAN tries to cheer',12))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. Bean  sees bernie in the airport scene\n",
            "A group of grave gentlemen and gentlewomen they are the trustees of\n",
            "BEAN tries to cheer him up he mimes an aeroplane which makes the boy feel n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4EZP958Id8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ee524d0b-da76-4198-c290-f829f6e59b2e"
      },
      "source": [
        "print(generate_seq(model, tokenizer, max_length-1, 'His eyes close, and',12))\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'His arm goes up',5))\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'BEAN then switches on',5))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "His eyes close, and the framed white rear gallery keys to the first gallery walks up\n",
            "His arm goes up and rings for the hostess\n",
            "BEAN then switches on the noisy overhead air blower\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy9lzcl1Kiqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}